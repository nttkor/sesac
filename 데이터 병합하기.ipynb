{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d953f30",
   "metadata": {
    "id": "0d953f30"
   },
   "source": [
    "# 데이터 병합하기\n",
    "\n",
    "데이터 병합은 여러 개의 데이터셋을 하나로 합치는 과정을 말합니다. 여러 개의 데이터셋이 각각 다른 정보를 담고 있을 때 이 데이터들을 합치면 데이터의 크기를 늘리거나 종합적인 정보를 얻을 수 있습니다. \n",
    "\n",
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JbP7t257_Jl5",
   "metadata": {
    "id": "JbP7t257_Jl5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(\"./data/seoul_park04.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfbb694",
   "metadata": {
    "id": "3dfbb694"
   },
   "source": [
    "## 데이터 병합: concat()\n",
    "\n",
    "먼저 데이터 확장을 위해 기존의 서울대공원 입장객 데이터에 이후 기간 데이터를 병합하는 과정을 알아보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871735c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ce65c2",
   "metadata": {},
   "source": [
    "실습에 활용하고있는 서울대공원 입장객 데이터는 2019년 3월 31일까지의 데이터가 담겨 있습니다. 이 데이터의 뒤에 2019년 4월 한달간의 데이터를 불러와서 합치면 2016년 1월 1일부터 2019년 4월 30일까지의 데이터를 만들 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5b0b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.read_csv(\"./data/seoul_park_april.csv\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25f02fe",
   "metadata": {},
   "source": [
    "`concat()`을 활용하면 두 개 이상의 데이터프레임을 행 또는 열 방향으로 단순히 이어붙이는데 활용합니다. 지금의 경우 2019년 3월 31일까지의 데이터인 `df`의 아래방향으로 2019년 4월의 데이터 `df2`를 이어붙이면 되기 때문에 `concat()`을 활용합니다.\n",
    "\n",
    "아래 방향으로 붙이기 때문에 `axis`를 **0**으로, 두 데이터프레임에 모두 존재하는 컬럼만을 남기기 위해 `join`을 **inner**로, 인덱스를 전체 초기화하기 위해 `ignore_index`를 **True**로 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e22da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df, df2], axis=0, join='inner', ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edfb749",
   "metadata": {},
   "source": [
    "`concat()`을 활용하여 2016년 1월 1일부터 2019년 4월 30일까지의 데이터를 만들었습니다. 이런식으로 데이터를 늘리면 더 긴 기간동안의 데이터를 분석할 수 있고 데이터 분석 결과의 정확도를 높일 수 있습니다.\n",
    "\n",
    "## 데이터 병합: merge()\n",
    "\n",
    "데이터 병합은 정보의 종류를 늘리는데도 활용할 수 있습니다. 서울대공원 데이터셋과 미세먼지 데이터셋을 합치면, 날씨 뿐 만 아니라 미세먼지 농도에 따른 입장객 수의 정보를 확인할 수도 있습니다. 서울대공원 데이터셋과 같은 기간동안 수집된 미세먼지 데이터를 불러오도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037aedfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm=pd.read_csv(\"./data/misemunji.csv\")\n",
    "mm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6cade6",
   "metadata": {},
   "source": [
    " **2016년 1월 1일부터 2019년 3월 31일까지의 서울대공원 입장객 데이터**에 **2016년 1월 1일부터 2019년 3월 31일까지의 미세먼지 데이터**를 합쳐보도록 하겠습니다. \n",
    " \n",
    "`merge()`를 활용해서 데이터를 합칠 때에는 기준이 될 컬럼이 필요합니다. 이번 경우에는 날짜를 기준으로 입장객수와 미세먼지 데이터간의 관계를 확인하기 위해 기준 컬럼인 `on`을 **날짜**로 하겠습니다.\n",
    "\n",
    "`how`는 데이터를 합치는 방법을 지정합니다. 데이터를 합치는 방법은 데이터 분석의 목적에 따라 달라지므로 각 방법을 선택하는 이유에 대한 이해가 필요합니다.\n",
    "\n",
    "우리의 관심사는 미세먼지에 따른 입장객의 수이기 때문에, 입장객 수 데이터가 없는 부분은 필요하지 않습니다. 두 데이터의 수집 기간은 같지만, 서울대공원 입장객 데이터의 경우 조류독감으로 인해 폐쇄된 구간의 데이터가 없기 때문에 해당 기간의 미세먼지 데이터는 필요가 없습니다. 따라서 입장객 수의 데이터가 존재하는 구간의 데이터만을 얻기 위해 `how`를 입장객 수 데이터, **left**에 맞춘 것입니다. (이번 실습의 경우 **inner**를 활용해도 같은 결과를 얻을 수 있습니다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1b64ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df, mm, on = '날짜', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96b3d52",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "fNhSv2TwxY0P",
    "outputId": "71b1c6ca-88a4-491d-eca8-712a8f946972",
    "scrolled": true
   },
   "source": [
    "이렇게 두 데이터를 날짜를 기준으로 합쳐서 더욱 더 다양한 정보가 담긴 데이터를 만들었습니다. 만약 이 데이터를 활용해서 데이터 분석이나 그래프를 그리는 시각화 등을 수행한다면 입장객 수와 미세먼지 농도의 관계를 파악할 수 있습니다.\n",
    "\n",
    "## [TODO] 다양한 데이터 병합 실습을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d3294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실습을 위한 데이터를 생성합니다.\n",
    "score = pd.DataFrame({\n",
    "    '이름': ['민수', '도윤', '서아', '연우', '하준'],\n",
    "    '국어': [95, 72, 83, 89, 100],\n",
    "    '수학': [88, 72, 93, 80, 95],\n",
    "    '영어': [96, 68, 85, 94, 93]},\n",
    ")\n",
    "\n",
    "add1 = pd.DataFrame({\n",
    "    '이름': ['지호', '준우', '예서'],\n",
    "    '국어': [88, 92, 100],\n",
    "    '수학': [97, 91, 100],\n",
    "    '영어': [87, 95, 97],\n",
    "    '역사': [95, 100, 92]}\n",
    ")\n",
    "\n",
    "add2 = pd.DataFrame({\n",
    "    '이름': ['민수', '서아', '하준'],\n",
    "    '과학': [93, 82, 89],\n",
    "    '프로그래밍': [97, 96, 94]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d5b99e",
   "metadata": {},
   "source": [
    "`score`에는 기존의 특별반 5명 학생들의 **이름**과 **국어, 수학, 영어** 점수가 담겨있습니다.\n",
    "| | 이름  | 국어  | 수학  | 영어  |\n",
    "|---|---|---|---|---|\n",
    "| 0 | 민수  | 95  | 88  | 96  |\n",
    "| 1 | 도윤  | 72  | 72  | 68  |\n",
    "| 2 | 서아  | 83  | 93  | 85  |\n",
    "| 3 | 연우  | 89  | 80  | 94  |\n",
    "| 4 | 하준  | 100 | 95  | 93  |\n",
    "\n",
    "`add1`에는 3명의 새로운 특별반 학생들의 **이름, 국어, 수학, 영어, 역사**점수가 기록되어 있습니다.\n",
    "\n",
    "| | 이름  | 국어  | 수학  | 영어  | 역사 |\n",
    "|---|---|---|---|---|---|\n",
    "| 0 | 지호  | 88  | 97  | 87  | 95 |\n",
    "| 1 | 준우  | 92  | 91  | 95  | 100 |\n",
    "| 2 | 예서  | 100  | 100  | 97  | 92 |\n",
    "\n",
    "`add2`에는 기존의 특별반 5명의 학생들 중 **과학**과 **프로그래밍**시험을 본 학생들의 시험점수가 **이름**과 함께 기록되어있습니다. \n",
    "\n",
    "| | 이름  | 과학  | 프로그래밍 |\n",
    "|---|---|---|---|\n",
    "| 0 | 민수  | 93  | 97  |\n",
    "| 1 | 서아  | 82  | 96  |\n",
    "| 2 | 하준  | 89  | 94  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e795201",
   "metadata": {},
   "source": [
    "### 1. `score`과 `add1`을 활용해 전체 특별반 8명 학생들의 **국어, 수학, 영어** 점수데이터를 만들어 `ans1`에 저장하세요.\n",
    "* Hint: `pd.concat()`을 활용하세요.\n",
    "* `ans1`에는 다음과 같은 데이터프레임이 저장되어야 합니다.\n",
    "| | 이름  | 국어  | 수학  | 영어  |\n",
    "|---|---|---|---|---|\n",
    "| 0 | 민수  | 95  | 88  | 96  |\n",
    "| 1 | 도윤  | 72  | 72  | 68  |\n",
    "| 2 | 서아  | 83  | 93  | 85  |\n",
    "| 3 | 연우  | 89  | 80  | 94  |\n",
    "| 4 | 하준  | 100 | 95  | 93  |\n",
    "| 5 | 지호  | 88  | 97  | 87  |\n",
    "| 6 | 준우  | 92  | 91  | 95  |\n",
    "| 7 | 예서  | 100  | 100  | 97  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9b81e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# None을 지우고 알맞은 코드를 입력하세요.\n",
    "ans1=None\n",
    "ans1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904133ff",
   "metadata": {},
   "source": [
    "### 2. `score`과 `add2`을 활용해 기존 특별반 학생들 중 **국어, 수학, 영어, 과학, 프로그래밍** 5개 과목의 시험을 모두 본 학생들의 점수데이터를 만들어 `ans2`에 저장하세요. \n",
    "* Hint: `pd.merge()`를 활용하세요.\n",
    "* `ans2`에는 다음과 같은 데이터프레임이 저장되어야 합니다.\n",
    "| | 이름  | 국어  | 수학  | 영어  | 과학  | 프로그래밍 |\n",
    "|--|---|---|---|---|---|---|\n",
    "| 0 | 민수  | 95  | 88  | 96  | 93  | 97  |\n",
    "| 1 |서아  | 83  | 93  | 85  | 82  | 96  |\n",
    "| 2 |하준  | 100 | 95  | 93  | 89  | 94  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d35c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# None을 지우고 알맞은 코드를 입력하세요.\n",
    "ans2=None\n",
    "ans2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e311cfdf",
   "metadata": {},
   "source": [
    "## 채점\n",
    "* **[TODO]** 중 수행하지 않은 부분이 없는지 확인하세요.\n",
    "* 채점을 위해 아래 코드를 실행한 뒤 우측 상단의 제출 버튼을 눌러주세요.\n",
    "* 코드 수정시 정상적인 채점이 이루어지지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79312e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "ans1.to_json(\"problem_1.json\")\n",
    "ans2.to_json(\"problem_2.json\")\n",
    "\n",
    "result = {}\n",
    "result[\"problem_1\"] = \"problem_1.json\"\n",
    "result[\"problem_2\"] = \"problem_2.json\"\n",
    "\n",
    "with open(\"result.json\", \"w\") as f:\n",
    "    json.dump(result, f)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
